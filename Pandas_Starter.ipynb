{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><center>Jupyter Notebook</center></h2>\n",
    "\n",
    "Jupyter notebooks can be very handy as it helps in combining code with the text. We can create presentations, or technical documents using notebook. Default jupyter notebook can be difficult to work with, particularly with large document with a lot of sections and subsections. Or even codes become difficult to read if the code includes lots of functions, loops etc.\n",
    "\n",
    "If you use jupyter notebook, please install the extension: nbextension. <a href=\"https://jupyter-contrib-nbextensions.readthedocs.io/en/latest/install.html\">check here for installations</a>\n",
    "\n",
    "After you install the extension, a new option will come up as shown Figure 1 (a). Click on it to and select the extension you want in your notebook as I have selected some in Figure 1(b). Once clicked, you can use those extensions.\n",
    "\n",
    "\n",
    "<img src=\"notebook.png\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><center>Pandas Dataframe</center></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas dataframe is very useful tool for preparing your data for building machine learning/ analytics models. You can think of pandas dataframe as a table (2-d matrix). All the operations in pandas are performed in parallel (when you have millions of rows of data, <b>do not attempt to run loop</b>, always think as how you can process it using pandas.\n",
    "\n",
    "This is just a short starter on Pandas. We cannot cover all the possible operations but please go through their documentation <a href='https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html'>here</a>. You can see all the possible operations you can do using pandas.\n",
    "\n",
    "As you go along, please print the data to see what is happening with different operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "- whenever we import any library in python, we use \"as\" when we want to provide a shortcut for that library import\n",
    "  for example, import numpy as np etc. Its just a short, otherwise, we will have to write numpy or pandas everywhere\n",
    "- when importing a library from python, we sometimes write as \"from sklearn import random_projection\", here from the library \n",
    "  of sklearn, we just want to import the module (function) we would like to import, otherwise, code becomes heavy unnecessary\n",
    "'''\n",
    "import pandas as pd \n",
    "import numpy as np    # along with pandas, numpy can be used for different operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Panda Operation</h3>\n",
    "    \n",
    "We first read the data. Whenever we read the data in jupyter notebook, the data is stored in RAM of the computer (local memory). Thus if the data is too big and RAM of the computer is low, code may not be able to load the data and will \"memory error\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>One hot encoding</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use a churn data (you can check the data). The data has information on user's of a telecom industry and they want to build a model if the user will churn or not. \n",
    "\n",
    "Majority of the columns are binary (0 or 1), except six columns. In three columns, tenure, MonthlyCharges, TotalCharges, the data is ratio data. In three columns, 'InternetService','Contract','PaymentMethod', have integer data but it is not binary, has two-three options. It is easier much easier for ML models to convert data columns into <b>one hot vector</b> where the number of options in a columns in not huge. \n",
    "\n",
    "One hot vector converts categorical data into binary data. For example, in a dataset, gender of user may be specified as \"male\", \"female\" or \"other\". Since ML models work with numbers, we need to convert it into numbers. We can assign 1 to female, 2 to male and 3 to others. However, for example, in linear regression, it does not make sense as why one category of gender should have higher value than other. We can create three new columns: gender_female, gender_male, gender_other. In these columns, if a user is male, the entry in gender_female = 0, gender_male =1 and gender_other = 0. There are advantages of one hot encoding:\n",
    "\n",
    "1. it becomes much easier to interpret the results when we use one hot encoder\n",
    "2. it can handle non-linearity (for example, 1,2,3 in gender does not make sense)\n",
    "3. one disadvantage is that it makes the optimization problem difficult to solve (as the variables have to be integer). But current optimization methods are sophisticated enough to handle this.\n",
    "4. personally, I use one hot vector wherever I can (with that I mean where the number of options in a column in not very high)\n",
    "\n",
    "For example, data in tenure column can also be converted into one hot vector (since the maximum is 72 and minimum is 1), we will need 72 new columns (increasing the number of variables increases the demand for data). Also, increasing value of tenure \"makes sense\" (or it is advantageous to keep it as it is). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Reading the Data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape (7043, 21)\n",
      "   customerID  gender  SeniorCitizen  Partner  Dependents  tenure  \\\n",
      "0  7590-VHVEG       0              0        1           0       1   \n",
      "1  5575-GNVDE       1              0        0           0      34   \n",
      "2  3668-QPYBK       1              0        0           0       2   \n",
      "\n",
      "   PhoneService  MultipleLines  InternetService  OnlineSecurity  ...  \\\n",
      "0             0              0                1               0  ...   \n",
      "1             1              0                1               1  ...   \n",
      "2             1              0                1               1  ...   \n",
      "\n",
      "   DeviceProtection  TechSupport  StreamingTV  StreamingMovies  Contract  \\\n",
      "0                 0            0            0                0         1   \n",
      "1                 1            0            0                0         2   \n",
      "2                 0            0            0                0         1   \n",
      "\n",
      "   PaperlessBilling  PaymentMethod  MonthlyCharges  TotalCharges Churn  \n",
      "0                 1              2           29.85         29.85     0  \n",
      "1                 0              3           56.95        1889.5     0  \n",
      "2                 1              3           53.85        108.15     1  \n",
      "\n",
      "[3 rows x 21 columns]\n",
      "Index(['customerID', 'gender', 'SeniorCitizen', 'Partner', 'Dependents',\n",
      "       'tenure', 'PhoneService', 'MultipleLines', 'InternetService',\n",
      "       'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport',\n",
      "       'StreamingTV', 'StreamingMovies', 'Contract', 'PaperlessBilling',\n",
      "       'PaymentMethod', 'MonthlyCharges', 'TotalCharges', 'Churn'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# reading data through pandas: it is similar to how we read SQL data\n",
    "data = pd.read_csv('churn.csv')\n",
    "\n",
    "# print the shape of data (many numpy functions work in pandas also : shape is a numpy function)\n",
    "print('shape',data.shape)\n",
    "\n",
    "# it will print the top n rows of the data, default value of n = 5\n",
    "n = 3\n",
    "print(data.head(n))\n",
    "\n",
    "# printing the names of the columns\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Converting to one hot encoding</h3>\n",
    "\n",
    "The three columns which had few integer options, we will convert them into one hot vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_change = ['InternetService','Contract','PaymentMethod']\n",
    "\n",
    "for c in columns_to_change:\n",
    "    oneHot = pd.get_dummies(data[c],prefix=c)  # prefix tells how new columns be named (prefex_values is how it is renamed)\n",
    "    data   = data.drop(c,axis = 1)             # we dont need the old column, THIS IS HOW A COLUMN IS DROPPED\n",
    "    data   = pd.concat([data,oneHot],axis=1)   # THIS IS HOW TWO DATAFRAMES ARE MERGED (INNER JOIN), axis 1 = columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PaymentMethod_0</th>\n",
       "      <th>PaymentMethod_1</th>\n",
       "      <th>PaymentMethod_2</th>\n",
       "      <th>PaymentMethod_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PaymentMethod_0  PaymentMethod_1  PaymentMethod_2  PaymentMethod_3\n",
       "0                0                0                1                0\n",
       "1                0                0                0                1\n",
       "2                0                0                0                1\n",
       "3                1                0                0                0\n",
       "4                0                0                1                0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here oneHot was the new dataframe with one hot vectors (it has the index values same as original data)\n",
    "# check for the first row that the value for PaymentMethod was 2, so column PaymentMethod_2 = 1, rest are all 0\n",
    "\n",
    "oneHot.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "female and senior: 568 total users: 7043\n",
      "gender               0.504756\n",
      "SeniorCitizen        0.162147\n",
      "Partner              0.483033\n",
      "Dependents           0.299588\n",
      "tenure              32.371149\n",
      "PhoneService         0.903166\n",
      "MultipleLines        0.421837\n",
      "InternetService      1.222916\n",
      "OnlineSecurity       0.286668\n",
      "OnlineBackup         0.344881\n",
      "DeviceProtection     0.343888\n",
      "TechSupport          0.290217\n",
      "StreamingTV          0.384353\n",
      "StreamingMovies      0.387903\n",
      "Contract             1.690473\n",
      "PaperlessBilling     0.592219\n",
      "PaymentMethod        1.574329\n",
      "MonthlyCharges      64.761692\n",
      "Churn                0.265370\n",
      "senior_female        0.080647\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "adding a new column\n",
    "suppoe we want to add a new column as multiplication of two columns\n",
    "we want to find number of female sennior citizens (Lets assume that 1 = male, 0 = female)\n",
    "ALL THE OPERATIONS ARE SUPER FAST AS THEY ARE CARRIED OUT IN PARALLEL\n",
    "'''\n",
    "\n",
    "# this line first creates a new column with values (1-data['gender']) and multiplies it with seniorCitizen\n",
    "data['senior_female'] = (1-data['gender'])*data['SeniorCitizen']\n",
    "\n",
    "print(\"female and senior:\",sum(data['senior_female']), \"total users:\", len(data))\n",
    "\n",
    "# deleting a column\n",
    "# deleting toalCharges as it is roughly multiplication of tenure and monthlyCharges\n",
    "del data['TotalCharges']\n",
    "\n",
    "# print and check the columnwise statistics np.sum() or np.mean, np.median: numpy and padas go hand in hand\n",
    "print(np.mean(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Accessing DataFrame data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns of the data frame can be accessed by two methods\n",
    "# 1. method 1\n",
    "customerIds = data['customerID']\n",
    "\n",
    "# 2. method 2\n",
    "customerIds = data.customerID           # make sure that the column name has no black spaces, otherwise it will not work\n",
    "\n",
    "# For accessing a unique value (from one row and one column), it can accessed as\n",
    "# 1. method 1\n",
    "user_2_id = data.iloc[1, 0]             # data.iloc[row_number, column_number]\n",
    "\n",
    "# 2. method 2\n",
    "user_2_id = data.iloc[1]['customerID']  # data.iloc[row_number][column_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Applying functions in pandas dataframes</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of users with tenure > 25: 3754\n",
      "number of users with tenure > 25: 3754\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "- there are two methods using which we can perform actions on a column\n",
    "- these actions are by default run in parallel so it is fastest method\n",
    "- checking if the tenure is more than 25 (first we create a new column and then use function)\n",
    "\n",
    "it uses lambda keywork to perform action on every datapoint in the column\n",
    "'''\n",
    "\n",
    "# method 1\n",
    "data['is_tenure_25'] = 1   # creating a new column with all values all 1\n",
    "data['is_tenure_25'] = data['tenure'].apply(lambda x:1 if x > 25 else 0)\n",
    "\n",
    "print('number of users with tenure > 25:',sum(data['is_tenure_25']))\n",
    "\n",
    "# using method 1, only small operations can be performed. If we want to perform complicated operations, we can create function\n",
    "\n",
    "def check_if_25(x):\n",
    "    if x > 25:\n",
    "        return(1)\n",
    "    else:\n",
    "        return(0)\n",
    "\n",
    "data['is_tenure_25'] = 1   # creating a new column with all values all 1\n",
    "data['is_tenure_25'] = data['tenure'].apply(lambda x:check_if_25(x))\n",
    "\n",
    "print('number of users with tenure > 25:',sum(data['is_tenure_25']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Selecting some data rows from the set</h3>\n",
    "\n",
    "Sometimes, we need to filter the data (for example, removing outliers in dataset). We can use the selection method to select the rows we want. Lets build an example where we will select users only when tenure is greater than 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    customerID  gender  SeniorCitizen  Partner  Dependents  tenure  \\\n",
      "30  3841-NFECX       0              1        1           0      71   \n",
      "50  8012-SOUDQ       0              1        0           0      43   \n",
      "52  6575-SUVOI       0              1        1           0      25   \n",
      "53  7495-OOKFY       0              1        1           0       8   \n",
      "54  4667-QONEA       0              1        1           1      60   \n",
      "\n",
      "    PhoneService  MultipleLines  InternetService  OnlineSecurity  ...  \\\n",
      "30             1              1                2               1  ...   \n",
      "50             1              1                2               0  ...   \n",
      "52             1              1                1               1  ...   \n",
      "53             1              1                2               0  ...   \n",
      "54             1              0                1               1  ...   \n",
      "\n",
      "    TechSupport  StreamingTV  StreamingMovies  Contract  PaperlessBilling  \\\n",
      "30            1            0                0         3                 1   \n",
      "50            0            1                0         1                 1   \n",
      "52            1            1                0         1                 1   \n",
      "53            0            0                0         1                 1   \n",
      "54            1            0                1         2                 1   \n",
      "\n",
      "    PaymentMethod  MonthlyCharges  Churn  senior_female  is_tenure_25  \n",
      "30              1           96.35      0              1             1  \n",
      "50              2           90.25      0              1             1  \n",
      "52              1           69.50      0              1             0  \n",
      "53              1           80.65      1              1             0  \n",
      "54              1           74.85      0              1             1  \n",
      "\n",
      "[5 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "# data_tenure will have data with tenure value greater than 25\n",
    "\n",
    "# in this method \"data['is_tenure_25']==1\" finds the index which satisfy the condition\n",
    "data_tenure = data[data['is_tenure_25']==1]\n",
    "\n",
    "# we can directly write any condition\n",
    "data_tenure = data[data['tenure']>25]\n",
    "\n",
    "# selecting senior female citizens\n",
    "data_senior_females = data[(data['gender']==0) & (data['SeniorCitizen']==1)]\n",
    "\n",
    "print(data_senior_females.head(5))   # check it will only have data where the conditions were satisfied"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>WORD OF CAUTION</h3>\n",
    "\n",
    "If you doing some operation that is changing the fundamental structure of the original data, always create a copy. DataFrames act like an array in python. If you create a new variable, say data2 = data, and modify data2, data1 will also be modified. therefore, use the copy function to create copies, it will not alter the main data.mad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a copy\n",
    "data_copy = pd.DataFrame.copy(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>SQL operations</h3>\n",
    "\n",
    "All the possible SQL operations can be performed using pandas, example, JOIN, APPEND, finding unique rows, aggregating the data (for example, mean or sum using a key, say, userID), groupBY, countBy, prderBy etc.\n",
    "\n",
    "Refer to some of the links:\n",
    "https://medium.com/jbennetcodes/how-to-rewrite-your-sql-queries-in-pandas-and-more-149d341fc53e\n",
    "https://towardsdatascience.com/sql-and-pandas-268f634a4f5d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customerID</th>\n",
       "      <th>gender</th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>Partner</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>tenure</th>\n",
       "      <th>PhoneService</th>\n",
       "      <th>MultipleLines</th>\n",
       "      <th>InternetService</th>\n",
       "      <th>OnlineSecurity</th>\n",
       "      <th>...</th>\n",
       "      <th>TechSupport</th>\n",
       "      <th>StreamingTV</th>\n",
       "      <th>StreamingMovies</th>\n",
       "      <th>Contract</th>\n",
       "      <th>PaperlessBilling</th>\n",
       "      <th>PaymentMethod</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>Churn</th>\n",
       "      <th>senior_female</th>\n",
       "      <th>is_tenure_25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>4586</td>\n",
       "      <td>7569-NMZYQ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>118.75</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6118</td>\n",
       "      <td>9924-JPRMC</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>118.20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4610</td>\n",
       "      <td>2889-FPWRM</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>117.80</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      customerID  gender  SeniorCitizen  Partner  Dependents  tenure  \\\n",
       "4586  7569-NMZYQ       0              0        1           1      72   \n",
       "6118  9924-JPRMC       1              0        0           0      72   \n",
       "4610  2889-FPWRM       1              0        1           0      72   \n",
       "\n",
       "      PhoneService  MultipleLines  InternetService  OnlineSecurity  ...  \\\n",
       "4586             1              1                2               1  ...   \n",
       "6118             1              1                2               1  ...   \n",
       "4610             1              1                2               1  ...   \n",
       "\n",
       "      TechSupport  StreamingTV  StreamingMovies  Contract  PaperlessBilling  \\\n",
       "4586            1            1                1         3                 1   \n",
       "6118            1            1                1         3                 1   \n",
       "4610            1            1                1         2                 1   \n",
       "\n",
       "      PaymentMethod  MonthlyCharges  Churn  senior_female  is_tenure_25  \n",
       "4586              0          118.75      0              0             1  \n",
       "6118              2          118.20      0              0             1  \n",
       "4610              0          117.80      1              0             1  \n",
       "\n",
       "[3 rows x 22 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# just as an example, create a new data by sorting based on the tenure (highest to lowest)\n",
    "data_copy = data_copy.sort_values(by=['tenure'], ascending=False)\n",
    "\n",
    "# sorting based on multiple conditions (sorting first by tenure, then by monthly payment)\n",
    "data_copy = data_copy.sort_values(by=['tenure','MonthlyCharges'], ascending=False)\n",
    "data_copy.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we discuss, how to use an existing ML library for building ML models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><center>Building ML models is Python</center></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the programming languages have different libraries for machine learning. There are a lot of developers and they create their own library for different machine learning models. For example, scikit learn or statsmodels. We can use the machine learning models we need from any of these libraries.\n",
    "\n",
    "However, Scikit-learn is the most widely used python library for machine learning in python. Given that different experts are involved in building the libraries for these ML models, these can be trusted. Scikit-learn is very easy to use.\n",
    "\n",
    "Please install scikit-learn if you haven't already. If you use Anaconda, it is already installed in it. Scikit-learn provides a list of <b>classical machine learning</b> models. It also provides all the parameters that are required in the model (these are called hyper-parameters - how to select the best parameters is a research in itself but if we have an understanding of how these parameters might affect our prediction, we can make intelligent guesses on the parameter values to select).\n",
    "\n",
    "We will explain it though an example in logistic regression.\n",
    "\n",
    "Scikit-learn is very easy to use because irrespective of the model, same functions are used everywhere (for example fit(X,Y) or predict(X) etc)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Building the data</h3>\n",
    "\n",
    "Use the data we have, after one hot encoding and construct the training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame.copy(data)\n",
    "del X['Churn']\n",
    "del X['customerID'] # it has to be deleted\n",
    "\n",
    "Y = data['Churn']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Importing libraries</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "------------- understanding scikit-learn library -----------\n",
    "just google scikit-learn logistic regression or any model, it will take you the page for that model\n",
    "\n",
    "import the models we want (example, train_test_split and logistic regression)\n",
    "we can think of sklearn as a big library, which has sub libraries called model_selection, linear_model \n",
    "                                                                           which has the sub-sub library we need\n",
    "                                                                           \n",
    "Check the page for all the inputs the algorithm demands, the outputs which can be obtained\n",
    "'''\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression, Lasso\n",
    "from sklearn.metrics import accuracy_score, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7043, 20) (5634, 20) (1409, 20) (5634,) (1409,)\n"
     ]
    }
   ],
   "source": [
    "# building test and train set\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html \n",
    "# thik link takes us to the inputs train_test function needs, it will return our data sets\n",
    "# check the library for what do test_size or random_state means\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# check that sum of two sets = data size, also the dimensions (columns) should not change\n",
    "print(X.shape,X_train.shape,X_test.shape,Y_train.shape,Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Logistic Regression</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8190205819730305\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "now that the data is ready, we can use Logistic regression function to get us the model results\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "\n",
    "check the link for all the hyperparameters required in logistic regression (gives the following)\n",
    "\n",
    "class sklearn.linear_model.LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=1.0, fit_intercept=True, \n",
    "                intercept_scaling=1, class_weight=None, random_state=None, solver='lbfgs', max_iter=100, \n",
    "                multi_class='auto', verbose=0, warm_start=False, n_jobs=None, l1_ratio=None)\n",
    "                \n",
    "read about weach of the these parameters. for example, if the data is unbalanced, we can use class weight to give more \n",
    "preferrence to the class with lower instances (for example, if 3% churn, it is important to give more weight to the \n",
    "data points where there is churn: it is an idea like SMOTE for unbalanced dataset). If we do not set these parameters, \n",
    "it will be set as the default value as given in the link.\n",
    "'''\n",
    "\n",
    "# setting the parameters. You can add or remove any parameter from the slogistic regression function\n",
    "# if not set by us, it will be set as default\n",
    "\n",
    "parameter = {'penalty':'l2', 'solver':'lbfgs', 'max_iter':1090, 'verbose':0, 'n_jobs':-1}\n",
    "\n",
    "model       = LogisticRegression(**parameter).fit(X_train, Y_train)\n",
    "y_pred      = model.predict(X_test)                 # predicting on the test data set\n",
    "predictions = [round(value) for value in y_pred]    # converting probability to binary\n",
    "accuracy    = accuracy_score(Y_test, predictions)   # finding the accuracy\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7189496096522356\n"
     ]
    }
   ],
   "source": [
    "# setting the weight parameters (weight for churn = total users/total churns) to give more weight to churn\n",
    "# how to add the weight parameter into the set of parameters we use.\n",
    "\n",
    "# dictionary\n",
    "weight = {1:len(Y_train)/sum(Y_train),0:1}\n",
    "\n",
    "parameter = {'penalty':'l2', 'solver':'lbfgs', 'max_iter':100, 'verbose':0, 'n_jobs':-1,'class_weight':weight}\n",
    "\n",
    "model       = LogisticRegression(**parameter).fit(X_train, Y_train)\n",
    "y_pred      = model.predict(X_test)                 # predicting on the test data set\n",
    "predictions = [round(value) for value in y_pred]    # converting probability to binary\n",
    "accuracy    = accuracy_score(Y_test, predictions)   # finding the accuracy\n",
    "print(accuracy)\n",
    "\n",
    "# in any IDE, we can write model. and then click tab button on keyboard. it will show all the options available for output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Lasso</h3>\n",
    "\n",
    "Similar to any scikit-learn logistic regression model, we can also check it for other models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7043, 20) (5634, 20) (1409, 20) (5634,) (1409,)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html\n",
    "\n",
    "Go to the link, read on all the hyperparameters, as what do they mean and how should we select the values for them\n",
    "\n",
    "class sklearn.linear_model.Lasso(alpha=1.0, fit_intercept=True, normalize=False, precompute=False, copy_X=True, \n",
    "                        max_iter=1000, tol=0.0001, warm_start=False, positive=False,\n",
    "                        random_state=None, selection='cyclic')[source]\n",
    "        \n",
    "'''\n",
    "\n",
    "# lets create a new example where we predict tenure (from the same data using lasso)\n",
    "\n",
    "X = pd.DataFrame.copy(data)\n",
    "del X['tenure']\n",
    "del X['customerID'] # it has to be deleted\n",
    "\n",
    "Y = data['tenure']\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# check that sum of two sets = data size, also the dimensions (columns) should not change\n",
    "print(X.shape,X_train.shape,X_test.shape,Y_train.shape,Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.6377098483404007\n"
     ]
    }
   ],
   "source": [
    "parameter = {'alpha':0.1, 'max_iter':1000}\n",
    "\n",
    "model      = Lasso(**parameter).fit(X_train, Y_train)\n",
    "y_pred     = model.predict(X_test)                 # predicting on the test data set\n",
    "r_score    = r2_score(Y_test, predictions)         # finding the accuracy\n",
    "print(r_score)\n",
    "\n",
    "# running this gives a r-square value of -1.63 (this counters the common misconception that r-square lies between 0 and 1)\n",
    "# r-square value can lie from negative infinity to 1"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "177.85px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
